{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd23f502-45c6-43a5-92a2-c5b9735449ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "audio covid-19  AI\n",
    "\n",
    "modified the [Baseline] code \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PyQt5 \n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "import librosa.display\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "CFG = {\n",
    "    'SR':16000,\n",
    "    'N_MFCC':32, # MFCC 벡터를 추출할 개수\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "\n",
    "train_df = pd.read_csv('open/train_data.csv')\n",
    "test_df = pd.read_csv('open/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f896cce2-0f47-4377-b2a1-95144e58581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wav 파일의 MFCC Feature와 상태정보를 합친 학습데이터를 불러옵니다.\n",
    "train_df = pd.read_csv('./train_mfcc_data3.csv')\n",
    "\n",
    "# 학습데이터를 모델의 input으로 들어갈 x와 label로 사용할 y로 분할\n",
    "train_x = train_df.drop(columns=['id', 'covid19'])\n",
    "train_y = train_df['covid19']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4a66ac7-c6db-4258-802a-9fedded85412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoding(ohe, x):\n",
    "    # 학습데이터로 부터 fit된 one-hot encoder (ohe)를 받아 transform 시켜주는 함수\n",
    "    encoded = ohe.transform(x['gender'].values.reshape(-1,1))\n",
    "    encoded_df = pd.DataFrame(encoded, columns=ohe.categories_[0])\n",
    "    x = pd.concat([x.drop(columns=['gender']), encoded_df], axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cade4609-22a8-40f1-936d-a8ec8ba90f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'gender' column의 경우 추가 전처리가 필요 -> OneHotEncoder 적용\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit(train_x['gender'].values.reshape(-1,1))\n",
    "train_x = onehot_encoding(ohe, train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3921a22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2663, 38) (1142, 38) (3805, 38)\n",
      "elapsed ...  18.37578535079956\n",
      "{'solver': 'adam', 'learning_rate_init': 0.01, 'hidden_layer_sizes': [35], 'batch_size': 'auto', 'alpha': 0.0001, 'activation': 'relu'}\n",
      "NN MLPClassifier, cross_val_score, accuracy: 0.9042 (+/- 0.0089)\n",
      "\t 95 percent confidence interval = [0.8868, 0.9216]\n",
      "test of train data: f1_macro scores = 0.4811449341208542\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import os, sys, time\n",
    "\n",
    "X_train, X_test, y_train, y_test=  train_test_split(train_x, train_y, test_size=0.3, random_state=128)\n",
    "\n",
    "print(X_train.shape, X_test.shape, train_x.shape)\n",
    "\n",
    "tuned_parameters = {\n",
    "    'activation': (['relu','logistic','tanh','identity']),\n",
    "    'hidden_layer_sizes': ([ [5],[15],[25],[35],[45],[55],[65],[75],[85],[95],[105],[115],[125], [135],[145],[155]]),\n",
    "    'alpha':     ([0.1,0.01, 0.001, 0.0001,0.0001]),\n",
    "    'batch_size':         ['auto'],\n",
    "    'learning_rate_init':    [0.01,0.001],\n",
    "    'solver': [\"adam\"]\n",
    "}\n",
    "\n",
    "clf =  RandomizedSearchCV(MLPClassifier(), tuned_parameters, cv=5, n_jobs=1, scoring='f1_macro')  \n",
    "\n",
    "st = time.time()\n",
    "clf_ = clf.fit(X_train, y_train)\n",
    "\n",
    "print('elapsed ... ', time.time()-st)\n",
    "\n",
    "print(clf.best_params_)\n",
    "a = clf.best_params_\n",
    "\n",
    "clf2 = MLPClassifier(solver=a['solver'],learning_rate_init=a['learning_rate_init'], hidden_layer_sizes=a['hidden_layer_sizes'], \n",
    "                           batch_size=a['batch_size'], alpha=a['alpha'], activation=a['activation'])\n",
    "\n",
    "clf_nn_opt = clf2.fit(X_train, y_train)\n",
    "\n",
    "scores_nn = cross_val_score(clf_nn_opt, X_train, y_train, cv=5)\n",
    "                \n",
    "m = scores_nn.mean()    \n",
    "s = scores_nn.std()\n",
    "ci_l = m - 1.96 * s        \n",
    "ci_u = m + 1.96 * s \n",
    "print('NN MLPClassifier, cross_val_score, accuracy: %0.4f (+/- %0.4f)' % (scores_nn.mean(), scores_nn.std()))\n",
    "print('\\t 95 percent confidence interval = [%5.4f, %5.4f]' % (ci_l, ci_u))\n",
    "\n",
    "## testing \n",
    "y_pred = clf_nn_opt.predict(X_test)\n",
    "\n",
    "res = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'test of train data: f1_macro scores = {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7789cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' support vector machine '''\n",
    "from sklearn import tree, svm\n",
    "from skle\n",
    "tuned_parameters = {\n",
    "        'C':            ([0.1, 0.01, 0.001, 1, 10, 100]),\n",
    "        'kernel':       ['linear', 'rbf','poly'],                \n",
    "        'degree':       ([1,2,3,4,5,6]),\n",
    "        'gamma':         [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "        #'tol':         [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        }\n",
    "\n",
    "clf =  RandomizedSearchCV(svm.SVC(), tuned_parameters, cv=5, n_jobs=1, scoring='f1_macro')   \n",
    "\n",
    "st = time.time()\n",
    "\n",
    "# hyper-parameter들을 try.\n",
    "\n",
    "clf_svm_search = clf.fit(X_train, y_train)\n",
    "\n",
    "print('elapsed ... ', time.time()-st)\n",
    "\n",
    "print(clf_svm_search)\n",
    "\n",
    "print(clf_svm_search.best_params_)\n",
    "print(clf_svm_search.best_score_)\n",
    "a = clf_svm_search.best_params_\n",
    "\n",
    "clf = svm.SVC(gamma=a['gamma'], kernel=a['kernel'], degree=a['degree'], C=a['C'], random_state=3333)\n",
    "\n",
    "print(clf)\n",
    "\n",
    "clf_svm_opt = clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf_svm_opt)\n",
    "\n",
    "scores_svm = cross_val_score(clf_svm_opt, X_train, y_train, cv=5)\n",
    "print('SVM, cross_val_score, accuracy: %0.4f (+/- %0.4f)' % (scores_svm.mean(), scores_svm.std()))\n",
    "print('\\t 95 percent confidence interval = [%5.4f, %5.4f]' % (ci_l, ci_u))\n",
    "\n",
    "\n",
    "## testing \n",
    "y_pred = clf_svm_opt.predict(X_test)\n",
    "\n",
    "res = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'[Support Vector Machine model] test of train data: f1_macro scores = {res}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c01a6966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed ...  0.0\n",
      "elapsed ...  99.8425190448761\n",
      "{'n_estimators': 200, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy'}\n",
      "[0.91557223 0.91557223 0.91557223 0.91541353 0.91541353]\n",
      "RFC, cross_val_score, accuracy: 0.9155 (+/- 0.0001)\n",
      "\t 95 percent confidence interval = [0.9154, 0.9157]\n",
      "[Random Forest model] test of train data: f1_macro scores = 0.48161597821152974\n"
     ]
    }
   ],
   "source": [
    "''' Random forest '''\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import os, sys, time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tuned_parameters = {\n",
    "    'n_estimators': ([100,200,300,400,500,600,700]),\n",
    "    'max_features': (['auto', 'sqrt', 'log2']),                   # precomputed,'poly', 'sigmoid'\n",
    "    'max_depth':    ([10,15,20,25,30,None]),\n",
    "    'criterion':    (['gini', 'entropy','log_loss']),\n",
    "    'min_samples_split':  [2,4,6,8,10,12,14,16],\n",
    "    'min_samples_leaf':   [2,4,6,8,10,12,14,16]\n",
    "    }\n",
    "st = time.time()\n",
    "clf = RandomizedSearchCV(RandomForestClassifier(), tuned_parameters, cv=5, n_jobs=1, scoring='f1_macro')     \n",
    "print('elapsed ... ', time.time()-st)\n",
    "\n",
    "st = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "print('elapsed ... ', time.time()-st)\n",
    "\n",
    "print(clf.best_params_)\n",
    "# print(clf.best_score_)\n",
    "# print(clf.best_estimator_.score)\n",
    "       \n",
    "a = clf.best_params_\n",
    "\n",
    "# use the above optimized parameters...    \n",
    "clf = RandomForestClassifier(n_estimators=a['n_estimators'], max_depth=a['max_depth'],min_samples_split=a['min_samples_split'], \n",
    "                                min_samples_leaf=a['min_samples_leaf'], max_features=a['max_features'],criterion=a['criterion'], random_state=3333)\n",
    "   \n",
    "clf_rf_opt = clf.fit(X_train,y_train)    \n",
    "    \n",
    "scores_rf = cross_val_score(clf_rf_opt, X_train, y_train, cv=5)\n",
    "\n",
    "print(scores_rf)\n",
    "m = scores_rf.mean()\n",
    "s = scores_rf.std()\n",
    "\n",
    "# calculate 95% confidence interval\n",
    "ci_l = m - 1.96 * s\n",
    "ci_u = m + 1.96 * s\n",
    "\n",
    "print('RFC, cross_val_score, accuracy: %0.4f (+/- %0.4f)' % (scores_rf.mean(), scores_rf.std()))\n",
    "print('\\t 95 percent confidence interval = [%5.4f, %5.4f]' % (ci_l, ci_u))      \n",
    "\n",
    "## testing \n",
    "y_pred = clf_rf_opt.predict(X_test)\n",
    "res = f1_score(y_test, y_pred, average='macro')\n",
    "print(f'[Random Forest model] test of train data: f1_macro scores = {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e2631e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'adam', 'learning_rate_init': 0.001, 'hidden_layer_sizes': [55], 'batch_size': 'auto', 'alpha': 0.001, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cf251c2-6cba-446f-ab6c-45236eec93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 위의 학습데이터를 전처리한 과정과 동일하게 test data에도 적용\n",
    "\n",
    "model = clf_rf_opt\n",
    "test_x = pd.read_csv('./test_mfcc_data3.csv')\n",
    "test_x = test_x.drop(columns=['id'])\n",
    "\n",
    "# Data Leakage에 유의하여 train data로만 학습된 ohe를 사용\n",
    "test_x = onehot_encoding(ohe, test_x)\n",
    "\n",
    "# Model 추론\n",
    "preds = model.predict(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91e91fa6-ef2c-418f-90f2-e5662abe51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['covid19'] = preds\n",
    "submission.to_csv('./submit1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd134681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
